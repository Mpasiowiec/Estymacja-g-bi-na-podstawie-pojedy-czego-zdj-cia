{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded NYU mat\n",
      "RGB Directory exists. Not extracting\n",
      "Extracting Normalized Depths...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1449/1449 [03:28<00:00,  6.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import os\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "# data path\n",
    "path_to_depth = './nyu_depth_v2_labeled.mat'\n",
    "\n",
    "# read mat file\n",
    "image_db = h5py.File(path_to_depth)\n",
    "print('Loaded NYU mat')    \n",
    "\n",
    "# [3, 480, 640]\n",
    "data_dir = 'nyu_depth_v2/rgb/'\n",
    "gt_dir = 'nyu_depth_v2/depth/'\n",
    "\n",
    "if not(os.path.exists(data_dir)):\n",
    "    os.makedirs(data_dir)\n",
    "    print('Extracting RGB...')\n",
    "    for i in tqdm(list(range(image_db['images'].shape[0]))):\n",
    "        img = Image.fromarray(image_db['images'][i].transpose(2,1,0))\n",
    "        img.save(data_dir + str(i) + '.jpg')\n",
    "        pass\n",
    "    print('Done')\n",
    "else:\n",
    "    print(\"RGB Directory exists. Not extracting\")\n",
    "    \n",
    "if not(os.path.exists(gt_dir)):\n",
    "    os.makedirs(gt_dir)\n",
    "    print('Extracting Normalized Depths...')\n",
    "    for i in tqdm(list(range(image_db['depths'].shape[0]))):\n",
    "        depth = Image.fromarray((image_db['depths'][i].transpose(1,0)*1000).astype(\"int\"))\n",
    "        \n",
    "        depth.save(gt_dir + str(i) + '.png')\n",
    "        pass\n",
    "    print('Done')\n",
    "else:\n",
    "    print(\"Depth Directory exists. Not extracting\")\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[275.20132, 275.20694, 275.22107, ..., 224.29442, 224.28577,\n",
       "        224.28233],\n",
       "       [275.1957 , 275.2013 , 275.2153 , ..., 224.2909 , 224.28232,\n",
       "        224.2789 ],\n",
       "       [275.18182, 275.18726, 275.20093, ..., 224.28207, 224.27371,\n",
       "        224.27039],\n",
       "       ...,\n",
       "       [219.80946, 219.80414, 219.79074, ..., 208.13298, 208.10538,\n",
       "        208.0945 ],\n",
       "       [219.79604, 219.79068, 219.7772 , ..., 208.16353, 208.13454,\n",
       "        208.12306],\n",
       "       [219.79068, 219.78528, 219.77184, ..., 208.17583, 208.14632,\n",
       "        208.13463]], dtype=float32)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((image_db['depths'][0].transpose(1,0))*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "cv2.imread(\"C:/Users/micha/OneDrive - SGH/Estymacja-glebi-na-podstawie-pojedynczego-zdejcia/data/nyu_depth_v2/depth/0.png\", cv2.IMREAD_ANYCOLOR |\n",
    "                           cv2.IMREAD_ANYDEPTH)/1000"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
