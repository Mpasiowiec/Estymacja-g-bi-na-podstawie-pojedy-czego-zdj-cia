{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Biblioteki i funkcje pomocnicze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\micha\\anaconda3\\envs\\pytorch-env\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import logging\n",
    "import os\n",
    "import shutil\n",
    "from datetime import datetime, timedelta\n",
    "from typing import List\n",
    "\n",
    "import torch\n",
    "from omegaconf import OmegaConf\n",
    "from torch.utils.data import ConcatDataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "from models.Marigold import MarigoldPipeline, get_Marigold\n",
    "from datasets import BaseDepthDataset, DatasetMode, get_dataset\n",
    "from datasets.mixed_sampler import MixedBatchSampler\n",
    "from trainers import get_trainer_cls\n",
    "from util.config_util import (\n",
    "    find_value_in_omegaconf,\n",
    "    recursive_load_config,\n",
    ")\n",
    "from util.depth_transform import (\n",
    "    DepthNormalizerBase,\n",
    "    get_depth_normalizer,\n",
    ")\n",
    "from util.logging_util import (\n",
    "    config_logging,\n",
    "    init_wandb,\n",
    "    load_wandb_job_id,\n",
    "    log_slurm_job_id,\n",
    "    save_wandb_job_id,\n",
    "    tb_logger,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Argumenty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # -------------------- Arguments --------------------\n",
    "# parser = argparse.ArgumentParser(description=\"Train your cute model!\")\n",
    "# parser.add_argument(\n",
    "#     \"--config\",\n",
    "#     type=str,\n",
    "#     default=\"config/train_marigold.yaml\",\n",
    "#     help=\"Path to config file.\",\n",
    "# )\n",
    "# parser.add_argument(\n",
    "#     \"--resume_run\",\n",
    "#     action=\"store\",\n",
    "#     default=None,\n",
    "#     help=\"Path of checkpoint to be resumed. If given, will ignore --config, and checkpoint in the config\",\n",
    "# )\n",
    "# parser.add_argument(\n",
    "#     \"--output_dir\",\n",
    "#     type=str,\n",
    "#     default=\"/content\",\n",
    "#     help=\"directory to save checkpoints\"\n",
    "# )\n",
    "# parser.add_argument(\n",
    "#     \"--no_cuda\",\n",
    "#     action=\"store_true\",\n",
    "#     help=\"Do not use cuda.\"\n",
    "# )\n",
    "# parser.add_argument(\n",
    "#     \"--exit_after\",\n",
    "#     type=int,\n",
    "#     default=-1,\n",
    "#     help=\"Save checkpoint and exit after X minutes.\",\n",
    "# )\n",
    "# parser.add_argument(\n",
    "#     \"--no_wandb\",\n",
    "#     action=\"store_true\",\n",
    "#     help=\"run without wandb\"\n",
    "#     )\n",
    "# parser.add_argument(\n",
    "#     \"--do_not_copy_data\",\n",
    "#     action=\"store_true\",\n",
    "#     help=\"On Slurm cluster, do not copy data to local scratch\",\n",
    "# )\n",
    "# parser.add_argument(\n",
    "#     \"--base_data_dir\",\n",
    "#     type=str,\n",
    "#     default='/content/drive/MyDrive/magisterka/dane',\n",
    "#     help=\"directory of training data\"\n",
    "# )\n",
    "# parser.add_argument(\n",
    "#     \"--base_ckpt_dir\",\n",
    "#     type=str,\n",
    "#     # default=\"/content/drive/MyDrive/magisterka/Estymacja-glebi-na-podstawie-pojedynczego-zdejcia/ckpt\",\n",
    "#     default=\"stabilityai\",\n",
    "#     help=\"directory of pretrained checkpoint\",\n",
    "# )\n",
    "# parser.add_argument(\n",
    "#     \"--add_datetime_prefix\",\n",
    "#     action=\"store_false\",\n",
    "#     help=\"Add datetime to the output folder name\",\n",
    "# )\n",
    "\n",
    "# args = parser.parse_args()\n",
    "\n",
    "class arguments():\n",
    "    def __init__(\n",
    "        self,\n",
    "        config = \"config/train_marigold.yaml\",\n",
    "        resume_run = None,\n",
    "        output_dir = \"/content\",\n",
    "        no_cuda = False,\n",
    "        exit_after = -1,\n",
    "        no_wandb = True,\n",
    "        do_not_copy_data = False,\n",
    "        base_data_dir = '/content/drive/MyDrive/magisterka/dane',\n",
    "        base_ckpt_dir = \"stabilityai\",\n",
    "        add_datetime_prefix = True\n",
    "        ) -> None:\n",
    "        \n",
    "        self.config = config\n",
    "        self.resume_run = resume_run\n",
    "        self.output_dir = output_dir\n",
    "        self.no_cuda = no_cuda\n",
    "        self.exit_after = exit_after\n",
    "        self.no_wandb = no_wandb\n",
    "        self.do_not_copy_data = do_not_copy_data\n",
    "        self.base_data_dir = base_data_dir\n",
    "        self.base_ckpt_dir = base_ckpt_dir\n",
    "        self.add_datetime_prefix = add_datetime_prefix\n",
    "        \n",
    "args = arguments()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inicjalizacja"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ścieżki "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start at 2024-07-19 11:44:54.921736\n"
     ]
    }
   ],
   "source": [
    "t_start = datetime.now()\n",
    "print(f\"start at {t_start}\")\n",
    "\n",
    "# -------------------- Initialization --------------------\n",
    "resume_run = args.resume_run\n",
    "output_dir = args.output_dir\n",
    "base_data_dir = args.base_data_dir\n",
    "base_ckpt_dir = args.base_ckpt_dir\n",
    "\n",
    "# Resume previous run\n",
    "if resume_run is not None:\n",
    "    print(f\"Resume run: {resume_run}\")\n",
    "    out_dir_run = os.path.dirname(os.path.dirname(resume_run))\n",
    "    job_name = os.path.basename(out_dir_run)\n",
    "    # Resume config file\n",
    "    cfg = OmegaConf.load(os.path.join(out_dir_run, \"config.yaml\"))\n",
    "else:\n",
    "    # Run from start\n",
    "    cfg = recursive_load_config(args.config)\n",
    "    # Full job name\n",
    "    pure_job_name = os.path.basename(args.config).split(\".\")[0]\n",
    "    # Add time prefix\n",
    "    if args.add_datetime_prefix:\n",
    "        job_name = f\"{t_start.strftime('%y_%m_%d-%H_%M_%S')}-{pure_job_name}\"\n",
    "    else:\n",
    "        job_name = pure_job_name\n",
    "    # Output dir\n",
    "    if output_dir is not None:\n",
    "        out_dir_run = os.path.join(output_dir, job_name)\n",
    "    else:\n",
    "        out_dir_run = os.path.join(\"./output\", job_name)\n",
    "    os.makedirs(out_dir_run, exist_ok=False)\n",
    "cfg_data = cfg.dataset\n",
    "\n",
    "# Other directories\n",
    "out_dir_ckpt = os.path.join(out_dir_run, \"checkpoint\")\n",
    "if not os.path.exists(out_dir_ckpt):\n",
    "    os.makedirs(out_dir_ckpt)\n",
    "out_dir_tb = os.path.join(out_dir_run, \"tensorboard\")\n",
    "if not os.path.exists(out_dir_tb):\n",
    "    os.makedirs(out_dir_tb)\n",
    "out_dir_eval = os.path.join(out_dir_run, \"evaluation\")\n",
    "if not os.path.exists(out_dir_eval):\n",
    "    os.makedirs(out_dir_eval)\n",
    "out_dir_vis = os.path.join(out_dir_run, \"visualization\")\n",
    "if not os.path.exists(out_dir_vis):\n",
    "    os.makedirs(out_dir_vis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loggi i snapshoty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 2024-07-19 11:44:55,242 - ERROR -jupyter.py - notebook_metadata >> Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      " 2024-07-19 11:44:55,420 - INFO -536584518.py - <module> >> device = cuda\n",
      " 2024-07-19 11:44:55,441 - INFO -536584518.py - <module> >> Config saved to /content\\24_07_19-11_44_54-train_marigold\\config.yaml\n",
      " 2024-07-19 11:44:55,628 - INFO -536584518.py - <module> >> Code snapshot saved to: /content\\24_07_19-11_44_54-train_marigold\\code_snapshot.tar\n"
     ]
    }
   ],
   "source": [
    "# -------------------- Logging settings --------------------\n",
    "config_logging(cfg.logging, out_dir=out_dir_run)\n",
    "logging.debug(f\"config: {cfg}\")\n",
    "\n",
    "# Initialize wandb\n",
    "if not args.no_wandb:\n",
    "    if resume_run is not None:\n",
    "        wandb_id = load_wandb_job_id(out_dir_run)\n",
    "        wandb_cfg_dic = {\n",
    "            \"id\": wandb_id,\n",
    "            \"resume\": \"must\",\n",
    "            **cfg.wandb,\n",
    "        }\n",
    "    else:\n",
    "        wandb_cfg_dic = {\n",
    "            \"config\": dict(cfg),\n",
    "            \"name\": job_name,\n",
    "            \"mode\": \"online\",\n",
    "            **cfg.wandb,\n",
    "        }\n",
    "    wandb_cfg_dic.update({\"dir\": out_dir_run})\n",
    "    wandb_run = init_wandb(enable=True, **wandb_cfg_dic)\n",
    "    save_wandb_job_id(wandb_run, out_dir_run)\n",
    "else:\n",
    "    init_wandb(enable=False)\n",
    "\n",
    "# Tensorboard (should be initialized after wandb)\n",
    "tb_logger.set_dir(out_dir_tb)\n",
    "log_slurm_job_id(step=0)\n",
    "\n",
    "# -------------------- Device --------------------\n",
    "cuda_avail = torch.cuda.is_available() and not args.no_cuda\n",
    "device = torch.device(\"cuda\" if cuda_avail else \"cpu\")\n",
    "logging.info(f\"device = {device}\")\n",
    "\n",
    "# -------------------- Snapshot of code and config --------------------\n",
    "if resume_run is None:\n",
    "    _output_path = os.path.join(out_dir_run, \"config.yaml\")\n",
    "    with open(_output_path, \"w+\") as f:\n",
    "        OmegaConf.save(config=cfg, f=f)\n",
    "    logging.info(f\"Config saved to {_output_path}\")\n",
    "    # Copy and tar code on the first run\n",
    "    _temp_code_dir = os.path.join(out_dir_run, \"code_tar\")\n",
    "    _code_snapshot_path = os.path.join(out_dir_run, \"code_snapshot.tar\")\n",
    "    os.system(\n",
    "        f\"rsync --relative -arhvz --quiet --filter=':- .gitignore' --exclude '.git' . '{_temp_code_dir}'\"\n",
    "    )\n",
    "    os.system(f\"tar -cf {_code_snapshot_path} {_temp_code_dir}\")\n",
    "    os.system(f\"rm -rf {_temp_code_dir}\")\n",
    "    logging.info(f\"Code snapshot saved to: {_code_snapshot_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Akumulacja gradientu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 2024-07-19 11:44:59,559 - INFO -3121392872.py - <module> >> Effective batch size: 16, accumulation steps: 16\n"
     ]
    }
   ],
   "source": [
    "# -------------------- Gradient accumulation steps --------------------\n",
    "eff_bs = cfg.dataloader.effective_batch_size\n",
    "accumulation_steps = eff_bs / cfg.dataloader.max_train_batch_size\n",
    "assert int(accumulation_steps) == accumulation_steps\n",
    "accumulation_steps = int(accumulation_steps)\n",
    "\n",
    "logging.info(\n",
    "    f\"Effective batch size: {eff_bs}, accumulation steps: {accumulation_steps}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dane"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Dataset does not exist at: /content/drive/MyDrive/magisterka/dane\\vkitti2",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 12\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Training dataset\u001b[39;00m\n\u001b[0;32m      9\u001b[0m depth_transform: DepthNormalizerBase \u001b[38;5;241m=\u001b[39m get_depth_normalizer(\n\u001b[0;32m     10\u001b[0m     cfg_normalizer\u001b[38;5;241m=\u001b[39mcfg\u001b[38;5;241m.\u001b[39mdepth_normalization\n\u001b[0;32m     11\u001b[0m )\n\u001b[1;32m---> 12\u001b[0m train_dataset: BaseDepthDataset \u001b[38;5;241m=\u001b[39m get_dataset(\n\u001b[0;32m     13\u001b[0m     cfg_data\u001b[38;5;241m.\u001b[39mtrain,\n\u001b[0;32m     14\u001b[0m     base_data_dir\u001b[38;5;241m=\u001b[39mbase_data_dir,\n\u001b[0;32m     15\u001b[0m     mode\u001b[38;5;241m=\u001b[39mDatasetMode\u001b[38;5;241m.\u001b[39mTRAIN,\n\u001b[0;32m     16\u001b[0m     augmentation_args\u001b[38;5;241m=\u001b[39mcfg\u001b[38;5;241m.\u001b[39maugmentation,\n\u001b[0;32m     17\u001b[0m     depth_transform\u001b[38;5;241m=\u001b[39mdepth_transform,\n\u001b[0;32m     18\u001b[0m )\n\u001b[0;32m     20\u001b[0m logging\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAugmentation: \u001b[39m\u001b[38;5;124m\"\u001b[39m, cfg\u001b[38;5;241m.\u001b[39maugmentation)\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmixed\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m==\u001b[39m cfg_data\u001b[38;5;241m.\u001b[39mtrain\u001b[38;5;241m.\u001b[39mname:\n",
      "File \u001b[1;32mc:\\Users\\micha\\OneDrive - SGH\\Estymacja-glebi-na-podstawie-pojedynczego-zdejcia\\datasets\\__init__.py:52\u001b[0m, in \u001b[0;36mget_dataset\u001b[1;34m(cfg_data_split, base_data_dir, mode, **kwargs)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m cfg_data_split\u001b[38;5;241m.\u001b[39mname \u001b[38;5;129;01min\u001b[39;00m dataset_name_class_dict\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m     51\u001b[0m     dataset_class \u001b[38;5;241m=\u001b[39m dataset_name_class_dict[cfg_data_split\u001b[38;5;241m.\u001b[39mname]\n\u001b[1;32m---> 52\u001b[0m     dataset \u001b[38;5;241m=\u001b[39m dataset_class(\n\u001b[0;32m     53\u001b[0m         mode\u001b[38;5;241m=\u001b[39mmode,\n\u001b[0;32m     54\u001b[0m         filename_ls_path\u001b[38;5;241m=\u001b[39mcfg_data_split\u001b[38;5;241m.\u001b[39mfilenames,\n\u001b[0;32m     55\u001b[0m         dataset_dir\u001b[38;5;241m=\u001b[39mos\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(base_data_dir, cfg_data_split\u001b[38;5;241m.\u001b[39mdir),\n\u001b[0;32m     56\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcfg_data_split,\n\u001b[0;32m     57\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m     58\u001b[0m     )\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     60\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\micha\\OneDrive - SGH\\Estymacja-glebi-na-podstawie-pojedynczego-zdejcia\\datasets\\vkitti2_dataset.py:36\u001b[0m, in \u001b[0;36mVKITTI2Dataset.__init__\u001b[1;34m(self, kitti_bm_crop, valid_mask_crop, **kwargs)\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[0;32m     31\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m     32\u001b[0m     kitti_bm_crop,  \u001b[38;5;66;03m# Crop to KITTI benchmark size\u001b[39;00m\n\u001b[0;32m     33\u001b[0m     valid_mask_crop,  \u001b[38;5;66;03m# Evaluation mask. [None, garg or eigen]\u001b[39;00m\n\u001b[0;32m     34\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m     35\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m---> 36\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\n\u001b[0;32m     37\u001b[0m         \u001b[38;5;66;03m# virtual KITTI data parameter\u001b[39;00m\n\u001b[0;32m     38\u001b[0m         min_depth\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-5\u001b[39m,\n\u001b[0;32m     39\u001b[0m         max_depth\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m80\u001b[39m,  \u001b[38;5;66;03m# 655.35\u001b[39;00m\n\u001b[0;32m     40\u001b[0m         has_filled_depth\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m     41\u001b[0m         name_mode\u001b[38;5;241m=\u001b[39mDepthFileNameMode\u001b[38;5;241m.\u001b[39mrgb_id,\n\u001b[0;32m     42\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m     43\u001b[0m     )\n\u001b[0;32m     44\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkitti_bm_crop \u001b[38;5;241m=\u001b[39m kitti_bm_crop\n\u001b[0;32m     45\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalid_mask_crop \u001b[38;5;241m=\u001b[39m valid_mask_crop\n",
      "File \u001b[1;32mc:\\Users\\micha\\OneDrive - SGH\\Estymacja-glebi-na-podstawie-pojedynczego-zdejcia\\datasets\\base_depth_dataset.py:74\u001b[0m, in \u001b[0;36mBaseDepthDataset.__init__\u001b[1;34m(self, mode, filename_ls_path, dataset_dir, disp_name, min_depth, max_depth, has_filled_depth, name_mode, depth_transform, augmentation_args, resize_to_hw, move_invalid_to_far_plane, rgb_transform, **kwargs)\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilename_ls_path \u001b[38;5;241m=\u001b[39m filename_ls_path\n\u001b[0;32m     73\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset_dir \u001b[38;5;241m=\u001b[39m dataset_dir\n\u001b[1;32m---> 74\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(\n\u001b[0;32m     75\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset_dir\n\u001b[0;32m     76\u001b[0m ), \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset does not exist at: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     77\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdisp_name \u001b[38;5;241m=\u001b[39m disp_name\n\u001b[0;32m     78\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhas_filled_depth \u001b[38;5;241m=\u001b[39m has_filled_depth\n",
      "\u001b[1;31mAssertionError\u001b[0m: Dataset does not exist at: /content/drive/MyDrive/magisterka/dane\\vkitti2"
     ]
    }
   ],
   "source": [
    "# -------------------- Data --------------------\n",
    "loader_seed = cfg.dataloader.seed\n",
    "if loader_seed is None:\n",
    "    loader_generator = None\n",
    "else:\n",
    "    loader_generator = torch.Generator().manual_seed(loader_seed)\n",
    "    \n",
    "# Training dataset\n",
    "depth_transform: DepthNormalizerBase = get_depth_normalizer(\n",
    "    cfg_normalizer=cfg.depth_normalization\n",
    ")\n",
    "train_dataset: BaseDepthDataset = get_dataset(\n",
    "    cfg_data.train,\n",
    "    base_data_dir=base_data_dir,\n",
    "    mode=DatasetMode.TRAIN,\n",
    "    augmentation_args=cfg.augmentation,\n",
    "    depth_transform=depth_transform,\n",
    ")\n",
    "\n",
    "logging.debug(\"Augmentation: \", cfg.augmentation)\n",
    "\n",
    "if \"mixed\" == cfg_data.train.name:\n",
    "    dataset_ls = train_dataset\n",
    "    assert len(cfg_data.train.prob_ls) == len(\n",
    "        dataset_ls\n",
    "    ), \"Lengths don't match: `prob_ls` and `dataset_list`\"\n",
    "    concat_dataset = ConcatDataset(dataset_ls)\n",
    "    mixed_sampler = MixedBatchSampler(\n",
    "        src_dataset_ls=dataset_ls,\n",
    "        batch_size=cfg.dataloader.max_train_batch_size,\n",
    "        drop_last=True,\n",
    "        prob=cfg_data.train.prob_ls,\n",
    "        shuffle=True,\n",
    "        generator=loader_generator,\n",
    "    )\n",
    "    train_loader = DataLoader(\n",
    "        concat_dataset,\n",
    "        batch_sampler=mixed_sampler,\n",
    "        num_workers=cfg.dataloader.num_workers,\n",
    "    )\n",
    "else:\n",
    "    train_loader = DataLoader(\n",
    "        dataset=train_dataset,\n",
    "        batch_size=cfg.dataloader.max_train_batch_size,\n",
    "        num_workers=cfg.dataloader.num_workers,\n",
    "        shuffle=True,\n",
    "        generator=loader_generator,\n",
    "    )\n",
    "# Validation dataset\n",
    "val_loaders: List[DataLoader] = []\n",
    "for _val_dic in cfg_data.val:\n",
    "    _val_dataset = get_dataset(\n",
    "        _val_dic,\n",
    "        base_data_dir=base_data_dir,\n",
    "        mode=DatasetMode.EVAL,\n",
    "    )\n",
    "    _val_loader = DataLoader(\n",
    "        dataset=_val_dataset,\n",
    "        batch_size=1,\n",
    "        shuffle=False,\n",
    "        num_workers=cfg.dataloader.num_workers,\n",
    "    )\n",
    "    val_loaders.append(_val_loader)\n",
    "\n",
    "# Visualization dataset\n",
    "vis_loaders: List[DataLoader] = []\n",
    "for _vis_dic in cfg_data.vis:\n",
    "    _vis_dataset = get_dataset(\n",
    "        _vis_dic,\n",
    "        base_data_dir=base_data_dir,\n",
    "        mode=DatasetMode.EVAL,\n",
    "    )\n",
    "    _vis_loader = DataLoader(\n",
    "        dataset=_vis_dataset,\n",
    "        batch_size=1,\n",
    "        shuffle=False,\n",
    "        num_workers=cfg.dataloader.num_workers,\n",
    "    )\n",
    "    vis_loaders.append(_vis_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# -------------------- Model --------------------\n",
    "_pipeline_kwargs = cfg.pipeline.kwargs if cfg.pipeline.kwargs is not None else {}\n",
    "model = MarigoldPipeline.from_pretrained(\n",
    "    os.path.join(base_ckpt_dir, cfg.model.pretrained_path), **_pipeline_kwargs\n",
    ")\n",
    "\n",
    "# -------------------- Trainer --------------------\n",
    "# Exit time\n",
    "if args.exit_after > 0:\n",
    "    t_end = t_start + timedelta(minutes=args.exit_after)\n",
    "    logging.info(f\"Will exit at {t_end}\")\n",
    "else:\n",
    "    t_end = None\n",
    "\n",
    "trainer_cls = get_trainer_cls(cfg.trainer.name)\n",
    "logging.debug(f\"Trainer: {trainer_cls}\")\n",
    "trainer = trainer_cls(\n",
    "    cfg=cfg,\n",
    "    model=model,\n",
    "    train_dataloader=train_loader,\n",
    "    device=device,\n",
    "    base_ckpt_dir=base_ckpt_dir,\n",
    "    out_dir_ckpt=out_dir_ckpt,\n",
    "    out_dir_eval=out_dir_eval,\n",
    "    out_dir_vis=out_dir_vis,\n",
    "    accumulation_steps=accumulation_steps,\n",
    "    val_dataloaders=val_loaders,\n",
    "    vis_dataloaders=vis_loaders,\n",
    ")\n",
    "\n",
    "# -------------------- Checkpoint --------------------\n",
    "if resume_run is not None:\n",
    "    trainer.load_checkpoint(\n",
    "        resume_run, load_trainer_state=True, resume_lr_scheduler=True\n",
    "    )\n",
    "\n",
    "# -------------------- Training & Evaluation Loop --------------------\n",
    "try:\n",
    "    trainer.train(t_end=t_end)\n",
    "except Exception as e:\n",
    "    logging.exception(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright 2023 Bingxin Ke, ETH Zurich. All rights reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "# --------------------------------------------------------------------------\n",
    "# If you find this code useful, we kindly ask you to cite our paper in your work.\n",
    "# Please find bibtex at: https://github.com/prs-eth/Marigold#-citation\n",
    "# If you use or adapt this code, please attribute to https://github.com/prs-eth/marigold.\n",
    "# More information about the method can be found at https://marigoldmonodepth.github.io\n",
    "# --------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "import logging\n",
    "import os\n",
    "import shutil\n",
    "from datetime import datetime\n",
    "from typing import List, Union\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from diffusers import DDPMScheduler\n",
    "from omegaconf import OmegaConf\n",
    "from torch.nn import Conv2d\n",
    "from torch.nn.parameter import Parameter\n",
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "\n",
    "from models.MiDas import *\n",
    "from models.TernausNest import *\n",
    "\n",
    "from util import metric\n",
    "from util.data_loader import skip_first_batches\n",
    "from util.logging_util import tb_logger, eval_dic_to_text\n",
    "from util.loss import get_loss\n",
    "from util.lr_scheduler import IterExponential\n",
    "from util.metric import MetricTracker\n",
    "from util.multi_res_noise import multi_res_noise_like\n",
    "from util.alignment import align_depth_least_square\n",
    "from util.seeding import generate_seed_sequence\n",
    "\n",
    "class NetTrainer:\n",
    "    def __init__(\n",
    "        self,\n",
    "        cfg: OmegaConf,\n",
    "        model,\n",
    "        train_dataloader: DataLoader,\n",
    "        device,\n",
    "        base_ckpt_dir,\n",
    "        out_dir_ckpt,\n",
    "        out_dir_eval,\n",
    "        out_dir_vis,\n",
    "        accumulation_steps: int,\n",
    "        val_dataloaders: List[DataLoader] = None,\n",
    "        vis_dataloaders: List[DataLoader] = None,\n",
    "    ):\n",
    "        self.cfg: OmegaConf = cfg\n",
    "        self.model: MarigoldPipeline = model\n",
    "        self.device = device\n",
    "        self.seed: Union[int, None] = (\n",
    "            self.cfg.trainer.init_seed\n",
    "        )  # used to generate seed sequence, set to `None` to train w/o seeding\n",
    "        self.out_dir_ckpt = out_dir_ckpt\n",
    "        self.out_dir_eval = out_dir_eval\n",
    "        self.out_dir_vis = out_dir_vis\n",
    "        self.train_loader: DataLoader = train_dataloader\n",
    "        self.val_loaders: List[DataLoader] = val_dataloaders\n",
    "        self.vis_loaders: List[DataLoader] = vis_dataloaders\n",
    "        self.accumulation_steps: int = accumulation_steps\n",
    "\n",
    "        # Adapt input layers\n",
    "        if 8 != self.model.unet.config[\"in_channels\"]:\n",
    "            self._replace_unet_conv_in()\n",
    "\n",
    "        # Encode empty text prompt\n",
    "        self.model.encode_empty_text()\n",
    "        self.empty_text_embed = self.model.empty_text_embed.detach().clone().to(device)\n",
    "        \n",
    "        try:\n",
    "          self.model.unet.enable_xformers_memory_efficient_attention()\n",
    "        except ValueError:\n",
    "          pass\n",
    "\n",
    "        # Trainability\n",
    "        self.model.vae.requires_grad_(False)\n",
    "        self.model.text_encoder.requires_grad_(False)\n",
    "        self.model.unet.requires_grad_(True)\n",
    "\n",
    "        # Optimizer !should be defined after input layer is adapted\n",
    "        lr = self.cfg.lr\n",
    "        self.optimizer = Adam(self.model.unet.parameters(), lr=lr)\n",
    "\n",
    "        # LR scheduler\n",
    "        lr_func = IterExponential(\n",
    "            total_iter_length=self.cfg.lr_scheduler.kwargs.total_iter,\n",
    "            final_ratio=self.cfg.lr_scheduler.kwargs.final_ratio,\n",
    "            warmup_steps=self.cfg.lr_scheduler.kwargs.warmup_steps,\n",
    "        )\n",
    "        self.lr_scheduler = LambdaLR(optimizer=self.optimizer, lr_lambda=lr_func)\n",
    "\n",
    "        # Loss\n",
    "        self.loss = get_loss(loss_name=self.cfg.loss.name, **self.cfg.loss.kwargs)\n",
    "\n",
    "        # Training noise scheduler\n",
    "        self.training_noise_scheduler: DDPMScheduler = DDPMScheduler.from_pretrained(\n",
    "            os.path.join(\n",
    "                base_ckpt_dir,\n",
    "                cfg.trainer.training_noise_scheduler.pretrained_path,\n",
    "                \"scheduler\",\n",
    "            )\n",
    "        )\n",
    "        self.prediction_type = self.training_noise_scheduler.config.prediction_type\n",
    "        assert (\n",
    "            self.prediction_type == self.model.scheduler.config.prediction_type\n",
    "        ), \"Different prediction types\"\n",
    "        self.scheduler_timesteps = (\n",
    "            self.training_noise_scheduler.config.num_train_timesteps\n",
    "        )\n",
    "\n",
    "        # Eval metrics\n",
    "        self.metric_funcs = [getattr(metric, _met) for _met in cfg.eval.eval_metrics]\n",
    "        self.train_metrics = MetricTracker(*[\"loss\"])\n",
    "        self.val_metrics = MetricTracker(*[m.__name__ for m in self.metric_funcs])\n",
    "        # main metric for best checkpoint saving\n",
    "        self.main_val_metric = cfg.validation.main_val_metric\n",
    "        self.main_val_metric_goal = cfg.validation.main_val_metric_goal\n",
    "        assert (\n",
    "            self.main_val_metric in cfg.eval.eval_metrics\n",
    "        ), f\"Main eval metric `{self.main_val_metric}` not found in evaluation metrics.\"\n",
    "        self.best_metric = 1e8 if \"minimize\" == self.main_val_metric_goal else -1e8\n",
    "\n",
    "        # Settings\n",
    "        self.max_epoch = self.cfg.max_epoch\n",
    "        self.max_iter = self.cfg.max_iter\n",
    "        self.gradient_accumulation_steps = accumulation_steps\n",
    "        self.gt_depth_type = self.cfg.gt_depth_type\n",
    "        self.gt_mask_type = self.cfg.gt_mask_type\n",
    "        self.save_period = self.cfg.trainer.save_period\n",
    "        self.backup_period = self.cfg.trainer.backup_period\n",
    "        self.val_period = self.cfg.trainer.validation_period\n",
    "        self.vis_period = self.cfg.trainer.visualization_period\n",
    "\n",
    "        # Multi-resolution noise\n",
    "        self.apply_multi_res_noise = self.cfg.multi_res_noise is not None\n",
    "        if self.apply_multi_res_noise:\n",
    "            self.mr_noise_strength = self.cfg.multi_res_noise.strength\n",
    "            self.annealed_mr_noise = self.cfg.multi_res_noise.annealed\n",
    "            self.mr_noise_downscale_strategy = (\n",
    "                self.cfg.multi_res_noise.downscale_strategy\n",
    "            )\n",
    "\n",
    "        # Internal variables\n",
    "        self.epoch = 1\n",
    "        self.n_batch_in_epoch = 0  # batch index in the epoch, used when resume training\n",
    "        self.effective_iter = 0  # how many times optimizer.step() is called\n",
    "        self.in_evaluation = False\n",
    "        self.global_seed_sequence: List = []  # consistent global seed sequence, used to seed random generator, to ensure consistency when resuming\n",
    "\n",
    "    def _replace_unet_conv_in(self):\n",
    "        # replace the first layer to accept 8 in_channels\n",
    "        _weight = self.model.unet.conv_in.weight.clone()  # [320, 4, 3, 3]\n",
    "        _bias = self.model.unet.conv_in.bias.clone()  # [320]\n",
    "        _weight = _weight.repeat((1, 2, 1, 1))  # Keep selected channel(s)\n",
    "        # half the activation magnitude\n",
    "        _weight *= 0.5\n",
    "        # new conv_in channel\n",
    "        _n_convin_out_channel = self.model.unet.conv_in.out_channels\n",
    "        _new_conv_in = Conv2d(\n",
    "            8, _n_convin_out_channel, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
    "        )\n",
    "        _new_conv_in.weight = Parameter(_weight)\n",
    "        _new_conv_in.bias = Parameter(_bias)\n",
    "        self.model.unet.conv_in = _new_conv_in\n",
    "        logging.info(\"Unet conv_in layer is replaced\")\n",
    "        # replace config\n",
    "        self.model.unet.config[\"in_channels\"] = 8\n",
    "        logging.info(\"Unet config is updated\")\n",
    "        return\n",
    "\n",
    "    def train(self, t_end=None):\n",
    "        logging.info(\"Start training\")\n",
    "\n",
    "        device = self.device\n",
    "        self.model.to(device)\n",
    "\n",
    "        if self.in_evaluation:\n",
    "            logging.info(\n",
    "                \"Last evaluation was not finished, will do evaluation before continue training.\"\n",
    "            )\n",
    "            self.validate()\n",
    "\n",
    "        self.train_metrics.reset()\n",
    "        accumulated_step = 0\n",
    "\n",
    "        for epoch in range(self.epoch, self.max_epoch + 1):\n",
    "            self.epoch = epoch\n",
    "            logging.debug(f\"epoch: {self.epoch}\")\n",
    "\n",
    "            # Skip previous batches when resume\n",
    "            for batch in skip_first_batches(self.train_loader, self.n_batch_in_epoch):\n",
    "                self.model.unet.train()\n",
    "\n",
    "                # globally consistent random generators\n",
    "                if self.seed is not None:\n",
    "                    local_seed = self._get_next_seed()\n",
    "                    rand_num_generator = torch.Generator(device=device)\n",
    "                    rand_num_generator.manual_seed(local_seed)\n",
    "                else:\n",
    "                    rand_num_generator = None\n",
    "\n",
    "                # >>> With gradient accumulation >>>\n",
    "\n",
    "                # Get data\n",
    "                rgb = batch[\"rgb_norm\"].to(device)\n",
    "                depth_gt_for_latent = batch[self.gt_depth_type].to(device)\n",
    "\n",
    "                if self.gt_mask_type is not None:\n",
    "                    valid_mask_for_latent = batch[self.gt_mask_type].to(device)\n",
    "                    invalid_mask = ~valid_mask_for_latent\n",
    "                    valid_mask_down = ~torch.max_pool2d(\n",
    "                        invalid_mask.float(), 8, 8\n",
    "                    ).bool()\n",
    "                    valid_mask_down = valid_mask_down.repeat((1, 4, 1, 1))\n",
    "                else:\n",
    "                    raise NotImplementedError\n",
    "\n",
    "                batch_size = rgb.shape[0]\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    # Encode image\n",
    "                    rgb_latent = self.model.encode_rgb(rgb)  # [B, 4, h, w]\n",
    "                    # Encode GT depth\n",
    "                    gt_depth_latent = self.encode_depth(\n",
    "                        depth_gt_for_latent\n",
    "                    )  # [B, 4, h, w]\n",
    "\n",
    "                # Sample a random timestep for each image\n",
    "                timesteps = torch.randint(\n",
    "                    0,\n",
    "                    self.scheduler_timesteps,\n",
    "                    (batch_size,),\n",
    "                    device=device,\n",
    "                    generator=rand_num_generator,\n",
    "                ).long()  # [B]\n",
    "\n",
    "                # Sample noise\n",
    "                if self.apply_multi_res_noise:\n",
    "                    strength = self.mr_noise_strength\n",
    "                    if self.annealed_mr_noise:\n",
    "                        # calculate strength depending on t\n",
    "                        strength = strength * (timesteps / self.scheduler_timesteps)\n",
    "                    noise = multi_res_noise_like(\n",
    "                        gt_depth_latent,\n",
    "                        strength=strength,\n",
    "                        downscale_strategy=self.mr_noise_downscale_strategy,\n",
    "                        generator=rand_num_generator,\n",
    "                        device=device,\n",
    "                    )\n",
    "                else:\n",
    "                    noise = torch.randn(\n",
    "                        gt_depth_latent.shape,\n",
    "                        device=device,\n",
    "                        generator=rand_num_generator,\n",
    "                    )  # [B, 4, h, w]\n",
    "\n",
    "                # Add noise to the latents (diffusion forward process)\n",
    "                noisy_latents = self.training_noise_scheduler.add_noise(\n",
    "                    gt_depth_latent, noise, timesteps\n",
    "                )  # [B, 4, h, w]\n",
    "\n",
    "                # Text embedding\n",
    "                text_embed = self.empty_text_embed.to(device).repeat(\n",
    "                    (batch_size, 1, 1)\n",
    "                )  # [B, 77, 1024]\n",
    "\n",
    "                # Concat rgb and depth latents\n",
    "                cat_latents = torch.cat(\n",
    "                    [rgb_latent, noisy_latents], dim=1\n",
    "                )  # [B, 8, h, w]\n",
    "                cat_latents = cat_latents.float()\n",
    "\n",
    "                # Predict the noise residual\n",
    "                model_pred = self.model.unet(\n",
    "                    cat_latents, timesteps, text_embed\n",
    "                ).sample  # [B, 4, h, w]\n",
    "                if torch.isnan(model_pred).any():\n",
    "                    logging.warning(\"model_pred contains NaN.\")\n",
    "\n",
    "                # Get the target for loss depending on the prediction type\n",
    "                if \"sample\" == self.prediction_type:\n",
    "                    target = gt_depth_latent\n",
    "                elif \"epsilon\" == self.prediction_type:\n",
    "                    target = noise\n",
    "                elif \"v_prediction\" == self.prediction_type:\n",
    "                    target = self.training_noise_scheduler.get_velocity(\n",
    "                        gt_depth_latent, noise, timesteps\n",
    "                    )  # [B, 4, h, w]\n",
    "                else:\n",
    "                    raise ValueError(f\"Unknown prediction type {self.prediction_type}\")\n",
    "\n",
    "                # Masked latent loss\n",
    "                if self.gt_mask_type is not None:\n",
    "                    latent_loss = self.loss(\n",
    "                        model_pred[valid_mask_down].float(),\n",
    "                        target[valid_mask_down].float(),\n",
    "                    )\n",
    "                else:\n",
    "                    latent_loss = self.loss(model_pred.float(), target.float())\n",
    "\n",
    "                loss = latent_loss.mean()\n",
    "\n",
    "                self.train_metrics.update(\"loss\", loss.item())\n",
    "\n",
    "                loss = loss / self.gradient_accumulation_steps\n",
    "                loss.backward()\n",
    "                accumulated_step += 1\n",
    "\n",
    "                self.n_batch_in_epoch += 1\n",
    "                # Practical batch end\n",
    "\n",
    "                # Perform optimization step\n",
    "                if accumulated_step >= self.gradient_accumulation_steps:\n",
    "                    self.optimizer.step()\n",
    "                    self.lr_scheduler.step()\n",
    "                    self.optimizer.zero_grad()\n",
    "                    accumulated_step = 0\n",
    "\n",
    "                    self.effective_iter += 1\n",
    "\n",
    "                    # Log to tensorboard\n",
    "                    accumulated_loss = self.train_metrics.result()[\"loss\"]\n",
    "                    tb_logger.log_dic(\n",
    "                        {\n",
    "                            f\"train/{k}\": v\n",
    "                            for k, v in self.train_metrics.result().items()\n",
    "                        },\n",
    "                        global_step=self.effective_iter,\n",
    "                    )\n",
    "                    tb_logger.writer.add_scalar(\n",
    "                        \"lr\",\n",
    "                        self.lr_scheduler.get_last_lr()[0],\n",
    "                        global_step=self.effective_iter,\n",
    "                    )\n",
    "                    tb_logger.writer.add_scalar(\n",
    "                        \"n_batch_in_epoch\",\n",
    "                        self.n_batch_in_epoch,\n",
    "                        global_step=self.effective_iter,\n",
    "                    )\n",
    "                    logging.info(\n",
    "                        f\"iter {self.effective_iter:5d} (epoch {epoch:2d}): loss={accumulated_loss:.5f}\"\n",
    "                    )\n",
    "                    self.train_metrics.reset()\n",
    "\n",
    "                    # Per-step callback\n",
    "                    self._train_step_callback()\n",
    "\n",
    "                    # End of training\n",
    "                    if self.max_iter > 0 and self.effective_iter >= self.max_iter:\n",
    "                        self.save_checkpoint(\n",
    "                            ckpt_name=self._get_backup_ckpt_name(),\n",
    "                            save_train_state=False,\n",
    "                        )\n",
    "                        logging.info(\"Training ended.\")\n",
    "                        return\n",
    "                    # Time's up\n",
    "                    elif t_end is not None and datetime.now() >= t_end:\n",
    "                        self.save_checkpoint(ckpt_name=\"latest\", save_train_state=True)\n",
    "                        logging.info(\"Time is up, training paused.\")\n",
    "                        return\n",
    "\n",
    "                    torch.cuda.empty_cache()\n",
    "                    # <<< Effective batch end <<<\n",
    "\n",
    "            # Epoch end\n",
    "            self.n_batch_in_epoch = 0\n",
    "\n",
    "    def encode_depth(self, depth_in):\n",
    "        # stack depth into 3-channel\n",
    "        stacked = self.stack_depth_images(depth_in)\n",
    "        # encode using VAE encoder\n",
    "        depth_latent = self.model.encode_rgb(stacked)\n",
    "        return depth_latent\n",
    "\n",
    "    @staticmethod\n",
    "    def stack_depth_images(depth_in):\n",
    "        if 4 == len(depth_in.shape):\n",
    "            stacked = depth_in.repeat(1, 3, 1, 1)\n",
    "        elif 3 == len(depth_in.shape):\n",
    "            stacked = depth_in.unsqueeze(1)\n",
    "            stacked = depth_in.repeat(1, 3, 1, 1)\n",
    "        return stacked\n",
    "\n",
    "    def _train_step_callback(self):\n",
    "        \"\"\"Executed after every iteration\"\"\"\n",
    "        # Save backup (with a larger interval, without training states)\n",
    "        if self.backup_period > 0 and 0 == self.effective_iter % self.backup_period:\n",
    "            self.save_checkpoint(\n",
    "                ckpt_name=self._get_backup_ckpt_name(), save_train_state=False\n",
    "            )\n",
    "\n",
    "        _is_latest_saved = False\n",
    "        # Validation\n",
    "        if self.val_period > 0 and 0 == self.effective_iter % self.val_period:\n",
    "            self.in_evaluation = True  # flag to do evaluation in resume run if validation is not finished\n",
    "            self.save_checkpoint(ckpt_name=\"latest\", save_train_state=True)\n",
    "            _is_latest_saved = True\n",
    "            self.validate()\n",
    "            self.in_evaluation = False\n",
    "            self.save_checkpoint(ckpt_name=\"latest\", save_train_state=True)\n",
    "\n",
    "        # Save training checkpoint (can be resumed)\n",
    "        if (\n",
    "            self.save_period > 0\n",
    "            and 0 == self.effective_iter % self.save_period\n",
    "            and not _is_latest_saved\n",
    "        ):\n",
    "            self.save_checkpoint(ckpt_name=\"latest\", save_train_state=True)\n",
    "\n",
    "        # Visualization\n",
    "        if self.vis_period > 0 and 0 == self.effective_iter % self.vis_period:\n",
    "            self.visualize()\n",
    "\n",
    "    def validate(self):\n",
    "        for i, val_loader in enumerate(self.val_loaders):\n",
    "            val_dataset_name = val_loader.dataset.disp_name\n",
    "            val_metric_dic = self.validate_single_dataset(\n",
    "                data_loader=val_loader, metric_tracker=self.val_metrics\n",
    "            )\n",
    "            logging.info(\n",
    "                f\"Iter {self.effective_iter}. Validation metrics on `{val_dataset_name}`: {val_metric_dic}\"\n",
    "            )\n",
    "            tb_logger.log_dic(\n",
    "                {f\"val/{val_dataset_name}/{k}\": v for k, v in val_metric_dic.items()},\n",
    "                global_step=self.effective_iter,\n",
    "            )\n",
    "            # save to file\n",
    "            eval_text = eval_dic_to_text(\n",
    "                val_metrics=val_metric_dic,\n",
    "                dataset_name=val_dataset_name,\n",
    "                sample_list_path=val_loader.dataset.filename_ls_path,\n",
    "            )\n",
    "            _save_to = os.path.join(\n",
    "                self.out_dir_eval,\n",
    "                f\"eval-{val_dataset_name}-iter{self.effective_iter:06d}.txt\",\n",
    "            )\n",
    "            with open(_save_to, \"w+\") as f:\n",
    "                f.write(eval_text)\n",
    "\n",
    "            # Update main eval metric\n",
    "            if 0 == i:\n",
    "                main_eval_metric = val_metric_dic[self.main_val_metric]\n",
    "                if (\n",
    "                    \"minimize\" == self.main_val_metric_goal\n",
    "                    and main_eval_metric < self.best_metric\n",
    "                    or \"maximize\" == self.main_val_metric_goal\n",
    "                    and main_eval_metric > self.best_metric\n",
    "                ):\n",
    "                    self.best_metric = main_eval_metric\n",
    "                    logging.info(\n",
    "                        f\"Best metric: {self.main_val_metric} = {self.best_metric} at iteration {self.effective_iter}\"\n",
    "                    )\n",
    "                    # Save a checkpoint\n",
    "                    self.save_checkpoint(\n",
    "                        ckpt_name=self._get_backup_ckpt_name(), save_train_state=False\n",
    "                    )\n",
    "\n",
    "    def visualize(self):\n",
    "        for val_loader in self.vis_loaders:\n",
    "            vis_dataset_name = val_loader.dataset.disp_name\n",
    "            vis_out_dir = os.path.join(\n",
    "                self.out_dir_vis, self._get_backup_ckpt_name(), vis_dataset_name\n",
    "            )\n",
    "            os.makedirs(vis_out_dir, exist_ok=True)\n",
    "            _ = self.validate_single_dataset(\n",
    "                data_loader=val_loader,\n",
    "                metric_tracker=self.val_metrics,\n",
    "                save_to_dir=vis_out_dir,\n",
    "            )\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def validate_single_dataset(\n",
    "        self,\n",
    "        data_loader: DataLoader,\n",
    "        metric_tracker: MetricTracker,\n",
    "        save_to_dir: str = None,\n",
    "    ):\n",
    "        self.model.to(self.device)\n",
    "        metric_tracker.reset()\n",
    "\n",
    "        # Generate seed sequence for consistent evaluation\n",
    "        val_init_seed = self.cfg.validation.init_seed\n",
    "        val_seed_ls = generate_seed_sequence(val_init_seed, len(data_loader))\n",
    "\n",
    "        for i, batch in enumerate(\n",
    "            tqdm(data_loader, desc=f\"evaluating on {data_loader.dataset.disp_name}\"),\n",
    "            start=1,\n",
    "        ):\n",
    "            assert 1 == data_loader.batch_size\n",
    "            # Read input image\n",
    "            rgb_int = batch[\"rgb_int\"].squeeze()  # [3, H, W]\n",
    "            # GT depth\n",
    "            depth_raw_ts = batch[\"depth_raw_linear\"].squeeze()\n",
    "            depth_raw = depth_raw_ts.numpy()\n",
    "            depth_raw_ts = depth_raw_ts.to(self.device)\n",
    "            valid_mask_ts = batch[\"valid_mask_raw\"].squeeze()\n",
    "            valid_mask = valid_mask_ts.numpy()\n",
    "            valid_mask_ts = valid_mask_ts.to(self.device)\n",
    "\n",
    "            # Random number generator\n",
    "            seed = val_seed_ls.pop()\n",
    "            if seed is None:\n",
    "                generator = None\n",
    "            else:\n",
    "                generator = torch.Generator(device=self.device)\n",
    "                generator.manual_seed(seed)\n",
    "\n",
    "            # Predict depth\n",
    "            pipe_out: MarigoldDepthOutput = self.model(\n",
    "                rgb_int,\n",
    "                denoising_steps=self.cfg.validation.denoising_steps,\n",
    "                ensemble_size=self.cfg.validation.ensemble_size,\n",
    "                processing_res=self.cfg.validation.processing_res,\n",
    "                match_input_res=self.cfg.validation.match_input_res,\n",
    "                generator=generator,\n",
    "                batch_size=1,  # use batch size 1 to increase reproducibility\n",
    "                color_map=None,\n",
    "                show_progress_bar=False,\n",
    "                resample_method=self.cfg.validation.resample_method,\n",
    "            )\n",
    "\n",
    "            depth_pred: np.ndarray = pipe_out.depth_np\n",
    "\n",
    "            if \"least_square\" == self.cfg.eval.alignment:\n",
    "                depth_pred, scale, shift = align_depth_least_square(\n",
    "                    gt_arr=depth_raw,\n",
    "                    pred_arr=depth_pred,\n",
    "                    valid_mask_arr=valid_mask,\n",
    "                    return_scale_shift=True,\n",
    "                    max_resolution=self.cfg.eval.align_max_res,\n",
    "                )\n",
    "            else:\n",
    "                raise RuntimeError(f\"Unknown alignment type: {self.cfg.eval.alignment}\")\n",
    "\n",
    "            # Clip to dataset min max\n",
    "            depth_pred = np.clip(\n",
    "                depth_pred,\n",
    "                a_min=data_loader.dataset.min_depth,\n",
    "                a_max=data_loader.dataset.max_depth,\n",
    "            )\n",
    "\n",
    "            # clip to d > 0 for evaluation\n",
    "            depth_pred = np.clip(depth_pred, a_min=1e-6, a_max=None)\n",
    "\n",
    "            # Evaluate\n",
    "            sample_metric = []\n",
    "            depth_pred_ts = torch.from_numpy(depth_pred).to(self.device)\n",
    "\n",
    "            for met_func in self.metric_funcs:\n",
    "                _metric_name = met_func.__name__\n",
    "                _metric = met_func(depth_pred_ts, depth_raw_ts, valid_mask_ts).item()\n",
    "                sample_metric.append(_metric.__str__())\n",
    "                metric_tracker.update(_metric_name, _metric)\n",
    "\n",
    "            # Save as 16-bit uint png\n",
    "            if save_to_dir is not None:\n",
    "                img_name = batch[\"rgb_relative_path\"][0].replace(\"/\", \"_\")\n",
    "                png_save_path = os.path.join(save_to_dir, f\"{img_name}.png\")\n",
    "                depth_to_save = (pipe_out.depth_np * 65535.0).astype(np.uint16)\n",
    "                Image.fromarray(depth_to_save).save(png_save_path, mode=\"I;16\")\n",
    "\n",
    "        return metric_tracker.result()\n",
    "\n",
    "    def _get_next_seed(self):\n",
    "        if 0 == len(self.global_seed_sequence):\n",
    "            self.global_seed_sequence = generate_seed_sequence(\n",
    "                initial_seed=self.seed,\n",
    "                length=self.max_iter * self.gradient_accumulation_steps,\n",
    "            )\n",
    "            logging.info(\n",
    "                f\"Global seed sequence is generated, length={len(self.global_seed_sequence)}\"\n",
    "            )\n",
    "        return self.global_seed_sequence.pop()\n",
    "\n",
    "    def save_checkpoint(self, ckpt_name, save_train_state):\n",
    "        ckpt_dir = os.path.join(self.out_dir_ckpt, ckpt_name)\n",
    "        logging.info(f\"Saving checkpoint to: {ckpt_dir}\")\n",
    "        # Backup previous checkpoint\n",
    "        temp_ckpt_dir = None\n",
    "        if os.path.exists(ckpt_dir) and os.path.isdir(ckpt_dir):\n",
    "            temp_ckpt_dir = os.path.join(\n",
    "                os.path.dirname(ckpt_dir), f\"_old_{os.path.basename(ckpt_dir)}\"\n",
    "            )\n",
    "            if os.path.exists(temp_ckpt_dir):\n",
    "                shutil.rmtree(temp_ckpt_dir, ignore_errors=True)\n",
    "            os.rename(ckpt_dir, temp_ckpt_dir)\n",
    "            logging.debug(f\"Old checkpoint is backed up at: {temp_ckpt_dir}\")\n",
    "\n",
    "        # Save UNet\n",
    "        unet_path = os.path.join(ckpt_dir, \"unet\")\n",
    "        self.model.unet.save_pretrained(unet_path, safe_serialization=False)\n",
    "        logging.info(f\"UNet is saved to: {unet_path}\")\n",
    "\n",
    "        if save_train_state:\n",
    "            state = {\n",
    "                \"optimizer\": self.optimizer.state_dict(),\n",
    "                \"lr_scheduler\": self.lr_scheduler.state_dict(),\n",
    "                \"config\": self.cfg,\n",
    "                \"effective_iter\": self.effective_iter,\n",
    "                \"epoch\": self.epoch,\n",
    "                \"n_batch_in_epoch\": self.n_batch_in_epoch,\n",
    "                \"best_metric\": self.best_metric,\n",
    "                \"in_evaluation\": self.in_evaluation,\n",
    "                \"global_seed_sequence\": self.global_seed_sequence,\n",
    "            }\n",
    "            train_state_path = os.path.join(ckpt_dir, \"trainer.ckpt\")\n",
    "            torch.save(state, train_state_path)\n",
    "            # iteration indicator\n",
    "            f = open(os.path.join(ckpt_dir, self._get_backup_ckpt_name()), \"w\")\n",
    "            f.close()\n",
    "\n",
    "            logging.info(f\"Trainer state is saved to: {train_state_path}\")\n",
    "\n",
    "        # Remove temp ckpt\n",
    "        if temp_ckpt_dir is not None and os.path.exists(temp_ckpt_dir):\n",
    "            shutil.rmtree(temp_ckpt_dir, ignore_errors=True)\n",
    "            logging.debug(\"Old checkpoint backup is removed.\")\n",
    "\n",
    "    def load_checkpoint(\n",
    "        self, ckpt_path, load_trainer_state=True, resume_lr_scheduler=True\n",
    "    ):\n",
    "        logging.info(f\"Loading checkpoint from: {ckpt_path}\")\n",
    "        # Load UNet\n",
    "        _model_path = os.path.join(ckpt_path, \"unet\", \"diffusion_pytorch_model.bin\")\n",
    "        self.model.unet.load_state_dict(\n",
    "            torch.load(_model_path, map_location=self.device)\n",
    "        )\n",
    "        self.model.unet.to(self.device)\n",
    "        logging.info(f\"UNet parameters are loaded from {_model_path}\")\n",
    "\n",
    "        # Load training states\n",
    "        if load_trainer_state:\n",
    "            checkpoint = torch.load(os.path.join(ckpt_path, \"trainer.ckpt\"))\n",
    "            self.effective_iter = checkpoint[\"effective_iter\"]\n",
    "            self.epoch = checkpoint[\"epoch\"]\n",
    "            self.n_batch_in_epoch = checkpoint[\"n_batch_in_epoch\"]\n",
    "            self.in_evaluation = checkpoint[\"in_evaluation\"]\n",
    "            self.global_seed_sequence = checkpoint[\"global_seed_sequence\"]\n",
    "\n",
    "            self.best_metric = checkpoint[\"best_metric\"]\n",
    "\n",
    "            self.optimizer.load_state_dict(checkpoint[\"optimizer\"])\n",
    "            logging.info(f\"optimizer state is loaded from {ckpt_path}\")\n",
    "\n",
    "            if resume_lr_scheduler:\n",
    "                self.lr_scheduler.load_state_dict(checkpoint[\"lr_scheduler\"])\n",
    "                logging.info(f\"LR scheduler state is loaded from {ckpt_path}\")\n",
    "\n",
    "        logging.info(\n",
    "            f\"Checkpoint loaded from: {ckpt_path}. Resume from iteration {self.effective_iter} (epoch {self.epoch})\"\n",
    "        )\n",
    "        return\n",
    "\n",
    "    def _get_backup_ckpt_name(self):\n",
    "        return f\"iter_{self.effective_iter:06d}\"\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
